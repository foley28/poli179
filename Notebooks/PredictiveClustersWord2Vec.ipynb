{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHOSB_cSNaHx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ursH-UGgNtrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "model = Word2Vec.load('/content/drive/MyDrive/Applied Deep Learning Poli Sci/Foley and Dorner Repo/Models/w2v100_tweets_model.model')\n",
        "\n",
        "word_vectors = model.wv.vectors"
      ],
      "metadata": {
        "id": "bm2dhORqWfBO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Load the JSON file into a dictionary\n",
        "with open('/content/drive/MyDrive/Applied Deep Learning Poli Sci/Foley and Dorner Repo/Models/word_to_cluster_model.json', 'r') as file:\n",
        "    word_to_cluster = json.load(file)\n",
        "\n",
        "# Convert the dictionary values to np.int32\n",
        "word_to_cluster = {word: np.int32(cluster) for word, cluster in word_to_cluster.items()}"
      ],
      "metadata": {
        "id": "w3Fq2mGHjY80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_merged = pd.read_csv('/content/drive/MyDrive/Applied Deep Learning Poli Sci/Foley and Dorner Repo/Data/final_merged.csv')\n",
        "user_data = pd.read_csv('/content/drive/MyDrive/Applied Deep Learning Poli Sci/Foley and Dorner Repo/Data/user_data.csv')\n",
        "bin_user = pd.read_csv('/content/drive/MyDrive/Applied Deep Learning Poli Sci/Foley and Dorner Repo/Data/bin_user.csv')\n",
        "\n",
        "#final_merged_int = pd.merge(final_merged, user_data, on='screen_name', how='left')\n",
        "#final_merged2 = pd.merge(final_merged_int, bin_user, on='screen_name', how='left')"
      ],
      "metadata": {
        "id": "JW9eu_jxcZxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model\n",
        "clf = joblib.load('/content/drive/MyDrive/Applied Deep Learning Poli Sci/Foley and Dorner Repo/Models/logistic_regression_model.pkl')\n",
        "\n",
        "# Extract the coefficients\n",
        "coefficients = clf.coef_\n",
        "\n",
        "# Assuming binary classification\n",
        "cluster_importance = np.abs(coefficients).mean(axis=0)  # Taking mean of absolute values across classes\n",
        "\n",
        "# Normalize the importance values for better visualization\n",
        "cluster_importance = cluster_importance / cluster_importance.max()\n",
        "\n",
        "# Get the indices of the top N most predictive clusters\n",
        "top_n = 10\n",
        "top_clusters_indices = np.argsort(cluster_importance)[-top_n:][::-1]\n",
        "\n",
        "# Print the indices of the top clusters\n",
        "print(f\"Indices of the top {top_n} most predictive clusters: {top_clusters_indices}\")\n",
        "\n",
        "# Assuming 'word_to_cluster' is a dictionary that maps words to their respective clusters\n",
        "# and 'model.wv.index_to_key' contains the list of words in the Word2Vec model\n",
        "\n",
        "# Create a dictionary to store words for each top cluster\n",
        "top_clusters_words = {index: [] for index in top_clusters_indices}\n",
        "\n",
        "# Populate the dictionary with words\n",
        "for word, cluster in word_to_cluster.items():\n",
        "    if cluster in top_clusters_indices:\n",
        "        top_clusters_words[cluster].append(word)\n",
        "\n",
        "# Display the words in each of the top clusters\n",
        "for cluster, words in top_clusters_words.items():\n",
        "    print(f\"Cluster {cluster}:\")\n",
        "    print(\", \".join(words[:20]))  # Displaying only the first 20 words for brevity\n",
        "    print()\n",
        "\n",
        "# Create a bar plot with labels for the top clusters\n",
        "plt.figure(figsize=(15, 7))\n",
        "bar_colors = ['red' if i in top_clusters_indices else 'blue' for i in range(len(cluster_importance))]\n",
        "sns.barplot(x=np.arange(len(cluster_importance)), y=cluster_importance, palette=bar_colors)\n",
        "\n",
        "# Add labels for the top clusters\n",
        "for i in top_clusters_indices:\n",
        "    plt.text(i, cluster_importance[i], f'{i}', ha='center', va='bottom', fontsize=10, color='black')\n",
        "\n",
        "plt.xlabel('Cluster Index')\n",
        "plt.ylabel('Importance')\n",
        "plt.title('Importance of Each Word2Vec Cluster in Predicting Ideologies')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NqM96IA3NtEI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
